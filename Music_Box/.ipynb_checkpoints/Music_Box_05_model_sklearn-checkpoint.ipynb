{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Box Churn Prediction and Recommendation using Spark\n",
    "\n",
    "# Using Scikit-learn to train model\n",
    "\n",
    "# Goal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/model_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot for `device_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['device_type_1'] = (df['device_type'] == 1).astype(int)\n",
    "df['device_type_2'] = (df['device_type'] == 2).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features.remove('uid')\n",
    "selected_features.remove('label')\n",
    "selected_features.remove('device_type')\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[selected_features].values\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build models\n",
    "\n",
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def get_performance_metrics(y_train, p_train_pred, y_test, p_test_pred, threshold=0.5):\n",
    "    metric_names = ['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score']\n",
    "    \n",
    "    metric_values_train = [roc_auc_score(y_train, p_train_pred),\n",
    "                           accuracy_score(y_train, p_train_pred > threshold),\n",
    "                           precision_score(y_train, p_train_pred > threshold),\n",
    "                           recall_score(y_train, p_train_pred > threshold),\n",
    "                           f1_score(y_train, p_train_pred > threshold)]\n",
    "    \n",
    "    metric_values_test = [roc_auc_score(y_test, p_test_pred),\n",
    "                          accuracy_score(y_test, p_test_pred > threshold),\n",
    "                          precision_score(y_test, p_test_pred > threshold),\n",
    "                          recall_score(y_test, p_test_pred > threshold),\n",
    "                          f1_score(y_test, p_test_pred > threshold)]\n",
    "    \n",
    "    all_metrics = pd.DataFrame({'metrics': metric_names,\n",
    "                                'train': metric_values_train,\n",
    "                                'test': metric_values_test},\n",
    "                                columns=['metrics', 'train', 'test'])\n",
    "\n",
    "    all_metrics.set_index('metrics')\n",
    "    print(all_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define ploting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curve(y_train, p_train_pred, y_test, p_test_pred):\n",
    "    roc_auc_train = roc_auc_score(y_train, p_train_pred)\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, p_train_pred)\n",
    "    \n",
    "    roc_auc_test = roc_auc_score(y_test, p_test_pred)\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, p_test_pred)\n",
    "    \n",
    "    lw = 2\n",
    "    plt.figure()\n",
    "    plt.plot(fpr_train, tpr_train, color='green', linewidth=lw, label = 'ROC Train (AUC = %0.4f)' % roc_auc_train)\n",
    "    plt.plot(fpr_test, tpr_test, color='darkorange', linewidth=lw, label='ROC Test (AUC = %0.4f)' % roc_auc_test)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linewidth=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model):\n",
    "    df_feature_importance = pd.DataFrame()\n",
    "    df_feature_importance['feature'] = selected_features\n",
    "    df_feature_importance['importance'] = model.feature_importances_\n",
    "    df_feature_importance.sort_values('importance', inplace=True)\n",
    "    \n",
    "    ax = df_feature_importance.plot(kind='barh', figsize=(20, 10))\n",
    "    t = np.arange(len(df_feature_importance['feature']))\n",
    "    ax.set_yticks(t)\n",
    "    ax.set_yticklabels(df_feature_importance['feature'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model and model performance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_train_prob = clf.predict_proba(X_train)[:, 1]\n",
    "    \n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    y_test_prob = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    get_performance_metrics(y_train, y_train_prob, y_test, y_test_prob)\n",
    "    plot_roc_curve(y_train, y_train_prob, y_test, y_test_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=0.3, penalty='l2')\n",
    "train_test_model(lr, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimated coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_values = zip(selected_features, lr.coef_.flatten()) # 把係數的名字和數值連結起來\n",
    "df_coeffs = pd.DataFrame(list(coef_values))\n",
    "df_coeffs.columns = ['feature', 'coeff']\n",
    "df_coeffs.sort_values(by='coeff', ascending=False, inplace=True)\n",
    "df_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_coeffs.plot.barh(figsize=(10,10)) # 水平的 bar 圖\n",
    "t = np.arange(X.shape[1])\n",
    "ax.set_yticks(t)\n",
    "ax.set_yticklabels(df_coeffs['feature'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=8, min_samples_leaf=20)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = dt.predict(X_train)\n",
    "p_train_pred = dt.predict_proba(X_train)[:, 1]\n",
    "\n",
    "y_test_pred = dt.predict(X_test)\n",
    "p_test_pred = dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_performance_metrics(y_train, p_train_pred, y_test, p_test_pred)\n",
    "plot_roc_curve(y_train, p_train_pred, y_test, p_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn import tree\n",
    "dot_data = tree.export_graphviz(dt, out_file=None,\n",
    "                                feature_names=selected_features,\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "parameters = {'base_estimator': dt,\n",
    "              'n_estimators': 100,\n",
    "              'n_jobs': -1}\n",
    "\n",
    "bagged_trees = BaggingClassifier(**parameters)\n",
    "\n",
    "train_test_model(bagged_trees, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "params = {'n_neighbors':10,\n",
    "          'leaf_size':100}\n",
    "\n",
    "knn = KNeighborsClassifier(**params)\n",
    "\n",
    "train_test_model(knn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "params = {'base_estimator': knn,\n",
    "          'n_estimators':30,\n",
    "          'n_jobs':-1}\n",
    "\n",
    "bagged_knn = BaggingClassifier(**params)\n",
    "\n",
    "train_test_model(bagged_knn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "parameters = {'n_estimators': 50,\n",
    "              'max_features': 'auto',\n",
    "              'criterion': 'gini',\n",
    "              'max_depth': 10,\n",
    "              'min_samples_split': 2,\n",
    "              'min_samples_leaf': 20,\n",
    "              'random_state': 0,\n",
    "              'n_jobs': -1}\n",
    "rf = RandomForestClassifier(**parameters)\n",
    "\n",
    "train_test_model(rf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# parameters = {\n",
    "#     'n_estimators': 50,\n",
    "#     'max_depth': 5,\n",
    "#     'learning_rate': 0.2,\n",
    "#     'subsample': 0.7,\n",
    "#     'max_features': 0.8,\n",
    "#     'random_state': 42\n",
    "# }\n",
    "\n",
    "gbt = GradientBoostingClassifier(**parameters)\n",
    "\n",
    "train_test_model(gbt, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(gbt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "parameters = {\n",
    "    'solver': 'adam',\n",
    "    'activation': 'relu',\n",
    "    'alpha': 1e-5, # increase alpha --> increase penalty\n",
    "    'hidden_layer_sizes': (5, 5),\n",
    "    'learning_rate': 'adaptive',\n",
    "    'random_state': 1\n",
    "}\n",
    "\n",
    "nn = MLPClassifier(**parameters)\n",
    "\n",
    "train_test_model(nn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning: Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['auto'],\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [5, 15, 20, 25],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [2, 5, 10, 20],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "acc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "grid_obj = GridSearchCV(clf, param_grid, cv=5, scoring=acc_scorer)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_test_model(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
