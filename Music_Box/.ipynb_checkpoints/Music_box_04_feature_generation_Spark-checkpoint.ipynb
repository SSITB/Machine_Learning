{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Box Churn Prediction and Recommendation using Spark\n",
    "\n",
    "# Using Spark to generate features\n",
    "\n",
    "## 1. Load data into Spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc = SparkContext('local')\n",
    "# spark = SparkSession(sc)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data/events.csv', header=True).cache()\n",
    "df # Show column names and types of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show() # default show 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert type of date column from `string` to `date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('date', F.col('date').cast('date'))\n",
    "df # notice the type of date column is date now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory data analysis\n",
    "\n",
    "#### Count number of rows\n",
    "\n",
    "```SQL\n",
    "SELECT COUNT(*)\n",
    "FROM event_ds_table;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 11,264,316 rows in the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count distinct `uid`\n",
    "\n",
    "```SQL\n",
    "SELECT COUNT(DISTINCT(uid))\n",
    "FROM event_ds_table;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('uid').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 51,637 users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group by\n",
    "\n",
    "```SQL\n",
    "SELECT COUNT(*)\n",
    "FROM events_ds_table\n",
    "GROUP BY event;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('event').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT COUNT(uid) as count, MAX(uid) as max_uid\n",
    "FROM event_ds_table\n",
    "GROUP BY event;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('event').agg(\n",
    "    F.count(F.col('uid')).alias('count'),\n",
    "    F.max(F.col('uid')).alias('max_uid')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter\n",
    "```SQL\n",
    "SELECT date, event, count(*)\n",
    "FROM event_ds_table\n",
    "WHERE date > '2017-04-01' AND date < '2017-04-10'\n",
    "GROUP BY date, event\n",
    "ORDER BY date, event\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter((F.col('date') > '2017-04-01') & \n",
    "          (F.col('date') <= '2017-04-10')).groupBy('date', 'event').count().orderBy('date', 'event').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_count = df.groupBy('date').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_count.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_count['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_count['date'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because I use `.groupBy('date')`, there are 44 days between 2017/3/30 to 2017/5/12. Therefore, the entries are 44."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "date_count.set_index('date').sort_values(by='date', ascending=True).plot.bar(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define labels\n",
    "\n",
    "The date is starting form 2017/3/30 to 2017/5/12. Total 44 days. Use the first 30 days as feature. and the last 14 days as labels.\n",
    "* Feature window: 2017/3/30 ~ 2017/4/28\n",
    "* Label window: 2017/4/29 ~ 2017/5/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "label_window_size = 14\n",
    "label_window_end_date = parser.parse('2017-05-12').date()\n",
    "label_window_start_date = label_window_end_date - datetime.timedelta(label_window_size - 1)\n",
    "print('label window: ', label_window_start_date, '~', label_window_end_date, ' days:', label_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_window_size = 30\n",
    "feature_window_end_date = label_window_start_date - datetime.timedelta(1)\n",
    "feature_window_start_date = feature_window_end_date - datetime.timedelta(feature_window_size - 1)\n",
    "print('Feature window: ', feature_window_start_date, '~', feature_window_end_date, ' days:', feature_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select unique `uid` in feature window (2017/3/30 ~ 2017/4/28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_uid = df.filter((F.col('date') >= feature_window_start_date) & \n",
    "                         (F.col('date') <= feature_window_end_date)).select('uid').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_uid.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_uid.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 51,637 users in 2017/3/30 to 2017/5/12 time window. And only 50,230 users in 2017/3/30 to 2017/4/28 feature window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set active user labels\n",
    "\n",
    "Define active users if they are activate in label window (2017/4/29 ~ 2017/5/12).\n",
    "* Active label = 0\n",
    "* Churn label = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_active_uid_in_label_window = df.filter((F.col('date') >= label_window_start_date) & \n",
    "                                          (F.col('date') <= label_window_end_date))\\\n",
    "                                  .select('uid').distinct().withColumn('label', F.lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = df_model_uid.join(df_active_uid_in_label_window, on='uid', how='left')\n",
    "df_label = df_label.fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature generation\n",
    "\n",
    "### Events in feature window\n",
    "\n",
    "Feature window: 2017/3/30 ~ 2017/4/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_window = df.filter((F.col('date') >= feature_window_start_date) & \n",
    "                              (F.col('date') <= feature_window_end_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency features\n",
    "\n",
    "#### Method1\n",
    "\n",
    "#### Define function to generate frequency features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_feature_generation(df, event, time_window, snapshot_date):\n",
    "    '''\n",
    "    Generate frequency features for one event type and one time window\n",
    "    '''\n",
    "    df_feature = df.filter(F.col('event') == event)\\\n",
    "                   .filter((F.col('date') >= snapshot_date - datetime.timedelta(time_window - 1)) &\n",
    "                           (F.col('date') <= snapshot_date))\\\n",
    "                   .groupBy('uid').agg(F.count(F.col('uid')).alias('freq_' + event + '_last_' + str(time_window)))\n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate one feature\n",
    "\n",
    "Select `uid` in 2017/4/19 ~ 2017/4/28 with `event='S'` and count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = 'S'\n",
    "time_window = 10\n",
    "snapshot_date = feature_window_end_date\n",
    "\n",
    "df_feature = frequency_feature_generation(df_feature_window, event, time_window, snapshot_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table counts the searching times for each user in the last 10 days of feature window (2017/4/19 to 2017/4/28)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate frequency features\n",
    "\n",
    "Select `uid` and count.\n",
    "\n",
    "|Time window | Date       |\n",
    "|-----------:|-----------:|\n",
    "|      1 day |        4/28|\n",
    "|     3 days | 4/26 ~ 4/28|\n",
    "|     7 days | 4/22 ~ 4/28|\n",
    "|    14 days | 4/15 ~ 4/28|\n",
    "|    30 days | 3/30 ~ 4/28|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_list = ['P', 'S', 'D']\n",
    "time_window_list = [1, 3, 7, 14, 30]\n",
    "df_feature_list = []\n",
    "\n",
    "for event in event_list:\n",
    "    for time_window in time_window_list:\n",
    "        df_feature_list.append(frequency_feature_generation(df_feature_window, event, time_window, snapshot_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for feature_list in df_feature_list:\n",
    "    feature_list.show(5)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `frequency_feature_generation()`, I got 15 tables. However, I would like to have a single table instead of 15 separated tables. The Method 2 can get 3 single tables, one for each event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2\n",
    "\n",
    "Use `when().otherwise()`\n",
    "\n",
    "`*[]` opens list and makes them comma separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_feature_generation_time_window(df, event, time_window_list, snapshot_date):\n",
    "    '''\n",
    "    Generate frequency features for one event type and a list of time window\n",
    "    '''\n",
    "    df_feature = df.filter(F.col('event') == event)\\\n",
    "                   .groupBy('uid')\\\n",
    "                   .agg(*[F.sum(F.when(\n",
    "                                        (F.col('date') >= snapshot_date - datetime.timedelta(time_window - 1)) &\n",
    "                                        (F.col('date') < snapshot_date)\n",
    "                                   , 1).otherwise(0)\\\n",
    "                               ).alias('freq_' + event + '_last_' + str(time_window)) \\\n",
    "                          for time_window in time_window_list])\n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate one event type for all time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = 'S'\n",
    "time_window_list = [1, 3, 7, 14, 30]\n",
    "snapshot_date = feature_window_end_date\n",
    "\n",
    "df_feature = frequency_feature_generation_time_window(df_feature_window, event, time_window_list, snapshot_date)\n",
    "df_feature.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate frequency features for all event_list and time_window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_list = ['P', 'S', 'D']\n",
    "time_window_list = [1, 3, 7, 14, 30]\n",
    "df_feature_list = []\n",
    "\n",
    "for event in event_list:\n",
    "    df_feature_list.append(frequency_feature_generation_time_window(df_feature_window, \n",
    "                                                                    event, \n",
    "                                                                    time_window_list, \n",
    "                                                                    snapshot_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_list in df_feature_list:\n",
    "    feature_list.show(5)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency features\n",
    "\n",
    "Find the last date of each user for each event. And count the number of days from last event date to 2017/4/28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defined as days from last event\n",
    "# can generate one feature for each type of event\n",
    "\n",
    "def days_from_last_event(df, event, snapshot_date):\n",
    "    # 一行就解決，不好懂\n",
    "#     df_days_from_last_event = df.filter(F.col('event') == event)\\\n",
    "#                                 .groupBy('uid')\\\n",
    "#                                 .agg(F.datediff(F.lit(snapshot_date), F.max('date')).alias('days_from_last_evnet'))\n",
    "    # 拆成下面兩行\n",
    "    # 先找出該 user 在 event 的最後一天\n",
    "    df_days_from_last_event = df.filter(F.col('event') == event)\\\n",
    "                                .groupBy('uid').agg(F.max('date').alias('last_date'))\n",
    "    # 再和 2017/4/28 比，看差幾天\n",
    "    df_days_from_last_event = df_days_from_last_event.withColumn('days_from_last_' + event + '_evnet', \n",
    "                                                                 F.datediff(F.lit(snapshot_date), F.col('last_date')))\\\n",
    "                                                     .select('uid', 'days_from_last_' + event + '_evnet')\n",
    "    return df_days_from_last_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_list = ['P', 'S', 'D']\n",
    "snapshot_date = feature_window_end_date\n",
    "df_days_list = []\n",
    "\n",
    "for event in event_list:\n",
    "    df_days_list.append(days_from_last_event(df_feature_window, event, snapshot_date))\n",
    "    \n",
    "for df_days in df_days_list:\n",
    "    df_days.show()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play = spark.read.csv('data/play.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play.select('uid').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 51635 users in the entire period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_feature_window = df_play.filter((F.col('date') >= feature_window_start_date) &\n",
    "                                        (F.col('date') <= feature_window_end_date))\n",
    "df_profile_tmp = df_play_feature_window.select('uid', 'device').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_feature_window.select('uid').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 49,856 out ouf 51,635 users in the feature window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile_tmp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile_tmp.groupBy('device').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if one user has two devices\n",
    "df_profile_tmp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile_tmp.distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 49,856 distince users but there are 49,866 rows. So 10 users have two devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now divide users in two groups, iPhone user and non-iPhone user\n",
    "* iPhone user: `device_type=1`\n",
    "* Non-iPhone user: `device_type=2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile_tmp = df_profile_tmp.withColumn('device_type', F.when(F.col('device') == 'ip', 1).otherwise(2))\n",
    "df_profile_tmp.groupBy('device_type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile = df_label.select('uid').join(df_profile_tmp.select('uid', 'device_type'), on='uid', how='left')\n",
    "df_profile.groupBy('device_type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 50,230 users in `df_label`. However, there are 10 users having two devices so there are 50,240 rows in `df_profile`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total play time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you generate total song play time features (using play_ds data) for different time window\n",
    "# using play data (need to clean play time first, play time may be negative in data)\n",
    "\n",
    "# Convert play_time and strong_length from string to integer\n",
    "df_play = df_play.withColumn('play_time', F.col('play_time').cast('integer'))\n",
    "df_play = df_play.withColumn('song_length', F.col('song_length').cast('integer'))\n",
    "df_play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only select those `play_time` > 0 and `song_length` > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_new = df_play.filter((F.col('play_time') > 0) & (F.col('song_length') > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_new.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_play_new.agg({'play_time':'max'}).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_play_new.agg({'play_time':'min'}).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_play_new.agg({'song_length':'max'}).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_play_new.agg({'song_length':'min'}).collect()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to remove the outlier in `play_time` and `song_length`. The outliers are defined as > mean + 3$\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_play_new.select(F.mean('play_time'), F.mean('song_length'), F.stddev('play_time'), F.stddev('song_length')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`play_time_mean = df_play_new.agg({'play_time': 'mean'}).collect()[0]` returns `Row(avg(play_time)=1448.893665371415`.\n",
    "\n",
    "However, I only want to get the value. So I need to add `asDict()` to convert row to dictionary. \n",
    "Then I can access the value using key.\n",
    "\n",
    "`play_time_mean = df_play_new.agg({'play_time': 'mean'}).collect()[0].asDict()` returns `{'avg(play_time)': 1448.893665371415}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_time_mean = df_play_new.agg({'play_time': 'mean'}).collect()[0].asDict()\n",
    "play_time_std = df_play_new.agg({'play_time': 'stddev'}).collect()[0].asDict()\n",
    "song_length_mean = df_play_new.agg({'song_length': 'mean'}).collect()[0].asDict()\n",
    "song_length_std = df_play_new.agg({'song_length': 'stddev'}).collect()[0].asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(play_time_mean))\n",
    "# print(play_time_mean, play_time_std, song_length_mean, song_length_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_outliers_removed = df_play_new.filter((F.col('play_time') <= play_time_mean['avg(play_time)'] + 3 * play_time_std['stddev(play_time)']) &\n",
    "                                              (F.col('song_length') <= song_length_mean['avg(song_length)'] + 3 * song_length_std['stddev(song_length)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_outliers_removed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_outliers_removed.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_outliers_removed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate total play time features for all event_list and time_window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_play_time_generation_time_window(df, time_window_list, snapshot_date):\n",
    "    '''\n",
    "    Generate frequency features for one event type and a list of time window\n",
    "    '''\n",
    "    df_feature = df.groupBy('uid')\\\n",
    "                   .agg(*[F.sum(F.when(\n",
    "                                        (F.col('date') >= snapshot_date - datetime.timedelta(time_window - 1)) &\n",
    "                                        (F.col('date') < snapshot_date)\n",
    "                                   , F.col('play_time')).otherwise(0)\\\n",
    "                               ).alias('total_play_time_' + str(time_window)) \\\n",
    "                          for time_window in time_window_list])\n",
    "                   \n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window_list = [1, 3, 7, 14, 30]\n",
    "snapshot_date = feature_window_end_date\n",
    "\n",
    "df_total_play_time = total_play_time_generation_time_window(df_play_outliers_removed, time_window_list, snapshot_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_play_time.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancier frequency features\n",
    "\n",
    "The units of `play_time` and `song_length` are in second. So $\\frac{play\\_time}{song\\_length} > 0.8$ stands for the songs play 80% of their length. However, the type of `play_time` and `song_length` are integer. I need to use `play_time` > 0.8 * `song_length` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you generate counts of songs play 80% of their song length (using play_ds data) for different time window\n",
    "# using play data (need to clean play time and song length first, play time may be negative in data, song length may be zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_eighty = df_play_outliers_removed.withColumn('eighty', F.when(F.col('play_time') > 0.8 * F.col('song_length'), 1).otherwise(0))\n",
    "df_play_eighty = df_play_eighty.select('uid', 'date', 'eighty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_eighty.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate total `play_time` / `song_length` > 0.8 features for all event_list and time_window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eighty_generation_time_window(df, time_window_list, snapshot_date):\n",
    "    '''\n",
    "    Generate frequency features for one event type and a list of time window\n",
    "    '''\n",
    "    df_feature = df.groupBy('uid')\\\n",
    "                   .agg(*[F.sum(F.when((F.col('date') >= snapshot_date - datetime.timedelta(time_window - 1)) &\n",
    "                                       (F.col('date') < snapshot_date),\n",
    "                                       F.when(F.col('play_time') > 0.8 * F.col('song_length'), 1).otherwise(0)\\\n",
    "                                      ).otherwise(0)\\\n",
    "                               ).alias('eighty_' + str(time_window)) \\\n",
    "                          for time_window in time_window_list])\n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window_list = [1, 3, 7, 14, 30]\n",
    "snapshot_date = feature_window_end_date\n",
    "\n",
    "df_eighty = eighty_generation_time_window(df_play_outliers_removed, time_window_list, snapshot_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eighty.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Form training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_feature_data(df_master, df_feature_list):\n",
    "    for df_feature in df_feature_list:\n",
    "        df_master = df_master.join(df_feature, on='uid', how='left')\n",
    "        #df_master.persist() # uncomment if number of joins is too many\n",
    "        \n",
    "    return df_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join all behavior features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_final = join_feature_data(df_label, df_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join all profile features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_final = join_feature_data(df_model_final, [df_profile])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join recency, total play time, and fancier frequency features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_final = join_feature_data(df_model_final, df_days_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_final = join_feature_data(df_model_final, [df_total_play_time, df_eighty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_model_final.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_model_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_final.fillna(0).toPandas().to_csv('data/model_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
